{
  "category": "Feature Enrichment",
  "description": "Representation learning to produce more discriminative embeddings for minority classes",
  "papers": [
    {
      "id": "zheng2024large",
      "title": "Large-scale long-tailed disease diagnosis on radiology images",
      "authors": "Zheng, Qiaoyu and Zhao, Weike and Wu, Chaoyi and Zhang, Xiaoman and Dai, Lisong and Guan, Hengyu and Li, Yuehua and Zhang, Ya and Wang, Yanfeng and Xie, Weidi",
      "year": "2024",
      "venue": "Nature Communications",
      "abstract": "Developing a generalist radiology diagnosis system can greatly enhance clinical diagnostics. In this paper, we introduce RadDiag, a foundational model supporting 2D and 3D inputs across various modalities and anatomies, using a transformer-based fusion module for comprehensive disease diagnosis. Due to patient privacy concerns and the lack of large-scale radiology diagnosis datasets, we utilize high-quality, clinician-reviewed radiological images available online with diagnosis labels. Our dataset, RP3D-DiagDS, contains 40,936 cases with 195,010 scans covering 5568 disorders (930 unique ICD-10-CM codes). Experimentally, our RadDiag achieves 95.14% AUC on internal evaluation with the knowledge-enhancement strategy. Additionally, RadDiag can be zero-shot applied or fine-tuned to external diagnosis datasets sourced from various medical centers, demonstrating state-of-the-art results. In conclusion, we show that publicly shared medical data on the Internet is a tremendous and valuable resource that can potentially support building strong models for image understanding in healthcare.",
      "bibtex": "@article{zheng2024large,\n  title={Large-scale long-tailed disease diagnosis on radiology images},\n  author={Zheng, Qiaoyu and Zhao, Weike and Wu, Chaoyi and Zhang, Xiaoman and Dai, Lisong and Guan, Hengyu and Li, Yuehua and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},\n  journal={Nature Communications},\n  volume={15},\n  number={1},\n  pages={10147},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n  abstract={Developing a generalist radiology diagnosis system can greatly enhance clinical diagnostics. In this paper, we introduce RadDiag, a foundational model supporting 2D and 3D inputs across various modalities and anatomies, using a transformer-based fusion module for comprehensive disease diagnosis. Due to patient privacy concerns and the lack of large-scale radiology diagnosis datasets, we utilize high-quality, clinician-reviewed radiological images available online with diagnosis labels. Our dataset, RP3D-DiagDS, contains 40,936 cases with 195,010 scans covering 5568 disorders (930 unique ICD-10-CM codes). Experimentally, our RadDiag achieves 95.14% AUC on internal evaluation with the knowledge-enhancement strategy. Additionally, RadDiag can be zero-shot applied or fine-tuned to external diagnosis datasets sourced from various medical centers, demonstrating state-of-the-art results. In conclusion, we show that publicly shared medical data on the Internet is a tremendous and valuable resource that can potentially support building strong models for image understanding in healthcare.}\n}"
    },
    {
      "id": "jang2024significantly",
      "title": "Significantly improving zero-shot X-ray pathology classification via fine-tuning pre-trained image-text encoders",
      "authors": "Jang, Jongseong and Kyung, Daeun and Kim, Seung Hwan and Lee, Honglak and Bae, Kyunghoon and Choi, Edward",
      "year": "2024",
      "venue": "Scientific Reports",
      "abstract": "Deep neural networks are increasingly used in medical imaging for tasks such as pathological classification, but they face challenges due to the scarcity of high-quality, expert-labeled training data. Recent efforts have utilized pre-trained contrastive image-text models like CLIP, adapting them for medical use by fine-tuning the model with chest X-ray images and corresponding reports for zero-shot pathology classification, thus eliminating the need for pathology-specific annotations. However, most studies continue to use the same contrastive learning objectives as in the general domain, overlooking the multi-labeled nature of medical image-report pairs. In this paper, we propose a new fine-tuning strategy that includes positive-pair loss relaxation and random sentence sampling. We aim to improve the performance of zero-shot pathology classification without relying on external knowledge. Our method can be applied to any pre-trained contrastive image-text encoder and easily transferred to out-of-domain datasets without further training, as it does not use external data. Our approach consistently improves overall zero-shot pathology classification across four chest X-ray datasets and three pre-trained models, with an average macro AUROC increase of 4.3%. Additionally, our method outperforms the state-of-the-art and marginally surpasses board-certified radiologists in zero-shot classification for the five competition pathologies in the CheXpert dataset.",
      "bibtex": "@article{jang2024significantly,\n  title={Significantly improving zero-shot X-ray pathology classification via fine-tuning pre-trained image-text encoders},\n  author={Jang, Jongseong and Kyung, Daeun and Kim, Seung Hwan and Lee, Honglak and Bae, Kyunghoon and Choi, Edward},\n  journal={Scientific Reports},\n  volume={14},\n  number={1},\n  pages={23199},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n  abstract={Deep neural networks are increasingly used in medical imaging for tasks such as pathological classification, but they face challenges due to the scarcity of high-quality, expert-labeled training data. Recent efforts have utilized pre-trained contrastive image-text models like CLIP, adapting them for medical use by fine-tuning the model with chest X-ray images and corresponding reports for zero-shot pathology classification, thus eliminating the need for pathology-specific annotations. However, most studies continue to use the same contrastive learning objectives as in the general domain, overlooking the multi-labeled nature of medical image-report pairs. In this paper, we propose a new fine-tuning strategy that includes positive-pair loss relaxation and random sentence sampling. We aim to improve the performance of zero-shot pathology classification without relying on external knowledge. Our method can be applied to any pre-trained contrastive image-text encoder and easily transferred to out-of-domain datasets without further training, as it does not use external data. Our approach consistently improves overall zero-shot pathology classification across four chest X-ray datasets and three pre-trained models, with an average macro AUROC increase of 4.3%. Additionally, our method outperforms the state-of-the-art and marginally surpasses board-certified radiologists in zero-shot classification for the five competition pathologies in the CheXpert dataset.}\n}"
    }
  ]
}