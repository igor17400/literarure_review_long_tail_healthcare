{
  "category": "Loss Functions",
  "description": "Loss function design for class-imbalanced learning",
  "papers": [
    {
      "id": "cong2024adaptive",
      "title": "Adaptive unified contrastive learning with graph-based feature aggregator for imbalanced medical image classification",
      "authors": "Cong, Cong and Liu, Sidong and Rana, Priyanka and Pagnucco, Maurice and Di Ieva, Antonio and Berkovsky, Shlomo and Song, Yang",
      "year": "2024",
      "venue": "Expert Systems with Applications",
      "abstract": "Medical image datasets are often imbalanced due to biases in data collection and limitations in acquiring data for rare conditions. Addressing class imbalance is crucial for developing reliable deep-learning algorithms capable of effectively handling all classes. Recent class imbalanced methods have investigated the effectiveness of self-supervised learning (SSL) and demonstrated that such learned features offer increased resilience to class imbalance issues and obtain much improved performances over other types of class imbalanced methods. However, existing SSL methods either lack end-to-end capabilities or require substantial memory resources, potentially resulting in sub-optimal features and classifiers and limiting their practical usage. Moreover, the conventional pooling operations (e.g., max-pooling, or average-pooling) tend to generate less discriminative features when datasets pose high inter-class similarities. To alleviate the above issues, in this study, we present a novel end-to-end self-supervised learning framework tailored for imbalanced medical image datasets. Our framework constitutes an adaptive contrastive loss that can dynamically adjust the model’s learning focus between feature learning and classifier learning and a feature aggregation mechanism based on Graph Neural Networks to further enhance feature discriminability. We evaluate the effectiveness of our framework on four medical datasets, and the experimental results highlight its superior performance in imbalanced image classification tasks.",
      "bibtex": "@article{cong2024adaptive,\n  title={Adaptive unified contrastive learning with graph-based feature aggregator for imbalanced medical image classification},\n  author={Cong, Cong and Liu, Sidong and Rana, Priyanka and Pagnucco, Maurice and Di Ieva, Antonio and Berkovsky, Shlomo and Song, Yang},\n  journal={Expert Systems with Applications},\n  volume={251},\n  pages={123783},\n  year={2024},\n  publisher={Elsevier}\n  abstract={Medical image datasets are often imbalanced due to biases in data collection and limitations in acquiring data for rare conditions. Addressing class imbalance is crucial for developing reliable deep-learning algorithms capable of effectively handling all classes. Recent class imbalanced methods have investigated the effectiveness of self-supervised learning (SSL) and demonstrated that such learned features offer increased resilience to class imbalance issues and obtain much improved performances over other types of class imbalanced methods. However, existing SSL methods either lack end-to-end capabilities or require substantial memory resources, potentially resulting in sub-optimal features and classifiers and limiting their practical usage. Moreover, the conventional pooling operations (e.g., max-pooling, or average-pooling) tend to generate less discriminative features when datasets pose high inter-class similarities. To alleviate the above issues, in this study, we present a novel end-to-end self-supervised learning framework tailored for imbalanced medical image datasets. Our framework constitutes an adaptive contrastive loss that can dynamically adjust the model’s learning focus between feature learning and classifier learning and a feature aggregation mechanism based on Graph Neural Networks to further enhance feature discriminability. We evaluate the effectiveness of our framework on four medical datasets, and the experimental results highlight its superior performance in imbalanced image classification tasks.}\n}"
    },
    {
      "id": "bae2025handling",
      "title": "Handling Imbalanced Medical Dataset with Continuous Class Features using Improved Contrastive Learning",
      "authors": "Bae, Jungwoo and Shin, Jitae",
      "year": "2025",
      "venue": "2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)",
      "abstract": "Medical datasets often face data imbalance due to challenges in collecting abnormal data, hindering reliable classification model development. Additionally, while severity-based categorical classes derived from continuous features aid patient understanding, unclear class definitions can lead models to overlook their continuous nature. Typically, these datasets are trained using contrastive learning methods, which focus solely on class-level distinctions without considering the underlying continuous information. In this paper, we propose an Improved Contrastive Learning method (ICL) to effectively learn from medical datasets that represent continuous nature as classes. Our approach incorporates curriculum learning in a two-phase learning framework. In Phase 1, original contrastive learning is applied. In Phase 2, we improve the learning process by sampling proxy lists based on class distribution parameters to address data imbalance and by updating class distance ratios to capture the continuous features between each classes. Our method outperforms existing approaches on the APTOS dataset. Furthermore, low-dimensional manifold visualizations of the learned representations reveal that disease features are progressively distributed according to class severity.",
      "bibtex": "@inproceedings{bae2025handling,\n  title={Handling Imbalanced Medical Dataset with Continuous Class Features using Improved Contrastive Learning},\n  author={Bae, Jungwoo and Shin, Jitae},\n  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)},\n  pages={0656--0660},\n  year={2025},\n  organization={IEEE}\n  abstract={Medical datasets often face data imbalance due to challenges in collecting abnormal data, hindering reliable classification model development. Additionally, while severity-based categorical classes derived from continuous features aid patient understanding, unclear class definitions can lead models to overlook their continuous nature. Typically, these datasets are trained using contrastive learning methods, which focus solely on class-level distinctions without considering the underlying continuous information. In this paper, we propose an Improved Contrastive Learning method (ICL) to effectively learn from medical datasets that represent continuous nature as classes. Our approach incorporates curriculum learning in a two-phase learning framework. In Phase 1, original contrastive learning is applied. In Phase 2, we improve the learning process by sampling proxy lists based on class distribution parameters to address data imbalance and by updating class distance ratios to capture the continuous features between each classes. Our method outperforms existing approaches on the APTOS dataset. Furthermore, low-dimensional manifold visualizations of the learned representations reveal that disease features are progressively distributed according to class severity.}\n}"
    },
    {
      "id": "cai2024bpaco",
      "title": "BPaCo: Balanced Parametric Contrastive Learning for Long-Tailed Medical Image Classification",
      "authors": "Cai, Zhiyuan and Wei, Tianyunxi and Lin, Li and Chen, Hao and Tang, Xiaoying",
      "year": "2024",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "abstract": "Medical image classification is an essential medical image analysis tasks. However, due to data scarcity of rare diseases in clinical scenarios, the acquired medical image datasets may exhibit long-tailed distributions. Previous works employ class re-balancing to address this issue yet the representation is usually not discriminative enough. Inspired by contrastive learning’s power in representation learning, in this paper, we propose and validate a contrastive learning based framework, named Balanced Parametric Contrastive learning (BPaCo), to tackle long-tailed medical image classification. There are three key components in BPaCo: across-batch class-averaging to balance the gradient contribution from negative classes; hybrid class-complement to have all classes appear in every mini-batch for discriminative prototypes; cross-entropy logit compensation to formulate an end-to-end classification framework with even stronger feature representations. Our BPaCo shows outstanding classification performance and high computational efficiency on three highly-imbalanced medical image classification datasets.",
      "bibtex": "@inproceedings{cai2024bpaco,\n  title={BPaCo: Balanced Parametric Contrastive Learning for Long-Tailed Medical Image Classification},\n  author={Cai, Zhiyuan and Wei, Tianyunxi and Lin, Li and Chen, Hao and Tang, Xiaoying},\n  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n  pages={383--393},\n  year={2024},\n  organization={Springer}\n  abstract={Medical image classification is an essential medical image analysis tasks. However, due to data scarcity of rare diseases in clinical scenarios, the acquired medical image datasets may exhibit long-tailed distributions. Previous works employ class re-balancing to address this issue yet the representation is usually not discriminative enough. Inspired by contrastive learning’s power in representation learning, in this paper, we propose and validate a contrastive learning based framework, named Balanced Parametric Contrastive learning (BPaCo), to tackle long-tailed medical image classification. There are three key components in BPaCo: across-batch class-averaging to balance the gradient contribution from negative classes; hybrid class-complement to have all classes appear in every mini-batch for discriminative prototypes; cross-entropy logit compensation to formulate an end-to-end classification framework with even stronger feature representations. Our BPaCo shows outstanding classification performance and high computational efficiency on three highly-imbalanced medical image classification datasets.}\n}"
    },
    {
      "id": "marrakchi2021fighting",
      "title": "Fighting class imbalance with contrastive learning",
      "authors": "Marrakchi, Yassine and Makansi, Osama and Brox, Thomas",
      "year": "2021",
      "venue": "International conference on medical image computing and computer-assisted intervention",
      "abstract": "edical image datasets are hard to collect, expensive to label, and often highly imbalanced. The last issue is underestimated, as typical average metrics hardly reveal that the often very important minority classes have a very low accuracy. In this paper, we address this problem by a feature embedding that balances the classes using contrastive learning as an alternative to the common cross-entropy loss. The approach is largely orthogonal to existing sampling methods and can be easily combined with those. We show on the challenging ISIC2018 and APTOS2019 datasets that the approach improves especially the accuracy of minority classes without negatively affecting the majority ones.",
      "bibtex": "@inproceedings{marrakchi2021fighting,\n  title={Fighting class imbalance with contrastive learning},\n  author={Marrakchi, Yassine and Makansi, Osama and Brox, Thomas},\n  booktitle={International conference on medical image computing and computer-assisted intervention},\n  pages={466--476},\n  year={2021},\n  organization={Springer}\n  abstract={edical image datasets are hard to collect, expensive to label, and often highly imbalanced. The last issue is underestimated, as typical average metrics hardly reveal that the often very important minority classes have a very low accuracy. In this paper, we address this problem by a feature embedding that balances the classes using contrastive learning as an alternative to the common cross-entropy loss. The approach is largely orthogonal to existing sampling methods and can be easily combined with those. We show on the challenging ISIC2018 and APTOS2019 datasets that the approach improves especially the accuracy of minority classes without negatively affecting the majority ones.}\n}"
    },
    {
      "id": "sadi2022lmfloss",
      "title": "LMFLOSS: A hybrid loss for imbalanced medical image classification",
      "authors": "Sadi, Abu Adnan and Chowdhury, Labib and Jahan, Nusrat and Rafi, Mohammad Newaz Sharif and Chowdhury, Radeya and Khan, Faisal Ahamed and Mohammed, Nabeel",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2212.12741",
      "abstract": "With advances in digital technology, the classification of medical images has become a crucial step for image-based clinical decision support systems. Automatic medical image classification represents a pivotal domain where the use of AI holds the potential to create a significant social impact. However, several challenges act as obstacles to the development of practical and effective solutions. One of these challenges is the prevalent class imbalance problem in most medical imaging datasets. As a result, existing AI techniques, particularly deep-learning-based methodologies, often underperform in such scenarios. In this study, we propose a novel framework called Large Margin aware Focal (LMF) loss to mitigate the class imbalance problem in medical imaging. The LMF loss represents a linear combination of two loss functions optimized by two hyperparameters. This framework harnesses the distinct characteristics of both loss functions by enforcing wider margins for minority classes while simultaneously emphasizing challenging samples found in the datasets. We perform rigorous experiments on three neural network architectures and with four medical imaging datasets. We provide empirical evidence that our proposed framework consistently outperforms other baseline methods, showing an improvement of 2%-9% in macro-f1 scores. Through class-wise analysis of f1 scores, we also demonstrate how the proposed framework can significantly improve performance for minority classes. The results of our experiments show that our proposed framework can perform consistently well across different architectures and datasets. Overall, our study demonstrates a simple and effective approach to addressing the class imbalance problem in medical imaging datasets. We hope our work will inspire new research toward a more generalized approach to medical image classification.",
      "bibtex": "@article{sadi2022lmfloss,\n  title={LMFLOSS: A hybrid loss for imbalanced medical image classification},\n  author={Sadi, Abu Adnan and Chowdhury, Labib and Jahan, Nusrat and Rafi, Mohammad Newaz Sharif and Chowdhury, Radeya and Khan, Faisal Ahamed and Mohammed, Nabeel},\n  journal={arXiv preprint arXiv:2212.12741},\n  year={2022}\n  abstract={With advances in digital technology, the classification of medical images has become a crucial step for image-based clinical decision support systems. Automatic medical image classification represents a pivotal domain where the use of AI holds the potential to create a significant social impact. However, several challenges act as obstacles to the development of practical and effective solutions. One of these challenges is the prevalent class imbalance problem in most medical imaging datasets. As a result, existing AI techniques, particularly deep-learning-based methodologies, often underperform in such scenarios. In this study, we propose a novel framework called Large Margin aware Focal (LMF) loss to mitigate the class imbalance problem in medical imaging. The LMF loss represents a linear combination of two loss functions optimized by two hyperparameters. This framework harnesses the distinct characteristics of both loss functions by enforcing wider margins for minority classes while simultaneously emphasizing challenging samples found in the datasets. We perform rigorous experiments on three neural network architectures and with four medical imaging datasets. We provide empirical evidence that our proposed framework consistently outperforms other baseline methods, showing an improvement of 2%-9% in macro-f1 scores. Through class-wise analysis of f1 scores, we also demonstrate how the proposed framework can significantly improve performance for minority classes. The results of our experiments show that our proposed framework can perform consistently well across different architectures and datasets. Overall, our study demonstrates a simple and effective approach to addressing the class imbalance problem in medical imaging datasets. We hope our work will inspire new research toward a more generalized approach to medical image classification.}\n}"
    },
    {
      "id": "singh2023batch",
      "title": "Batch-balanced focal loss: a hybrid solution to class imbalance in deep learning",
      "authors": "Singh, Jatin and Beeche, Cameron and Shi, Zhiyi and Beale, Oliver and Rosin, Boris and Leader, Joseph and Pu, Jiantao",
      "year": "2023",
      "venue": "Journal of Medical Imaging",
      "abstract": "Purpose: To validate the effectiveness of an approach called batch-balanced focal loss (BBFL) in enhancing convolutional neural network (CNN) classification performance on imbalanced datasets. Materials and methods: BBFL combines two strategies to tackle class imbalance: (1) batch-balancing to equalize model learning of class samples and (2) focal loss to add hard-sample importance to the learning gradient. BBFL was validated on two imbalanced fundus image datasets: a binary retinal nerve fiber layer defect (RNFLD) dataset ( n = 7,258 ) and a multiclass glaucoma dataset ( n = 7,873 ). BBFL was compared to several imbalanced learning techniques, including random oversampling (ROS), cost-sensitive learning, and thresholding, based on three state-of-the-art CNNs. Accuracy, F1-score, and the area under the receiver operator characteristic curve (AUC) were used as the performance metrics for binary classification. Mean accuracy and mean F1-score were used for multiclass classification. Confusion matrices, t-distributed neighbor embedding plots, and GradCAM were used for the visual assessment of performance. Results: In binary classification of RNFLD, BBFL with InceptionV3 (93.0% accuracy, 84.7% F1, 0.971 AUC) outperformed ROS (92.6% accuracy, 83.7% F1, 0.964 AUC), cost-sensitive learning (92.5% accuracy, 83.8% F1, 0.962 AUC), and thresholding (91.9% accuracy, 83.0% F1, 0.962 AUC) and others. In multiclass classification of glaucoma, BBFL with MobileNetV2 (79.7% accuracy, 69.6% average F1 score) outperformed ROS (76.8% accuracy, 64.7% F1), cost-sensitive learning (78.3% accuracy, 67.8.8% F1), and random undersampling (76.5% accuracy, 66.5% F1). Conclusion: The BBFL-based learning method can improve the performance of a CNN model in both binary and multiclass disease classification when the data are imbalanced.",
      "bibtex": "@article{singh2023batch,\n  title={Batch-balanced focal loss: a hybrid solution to class imbalance in deep learning},\n  author={Singh, Jatin and Beeche, Cameron and Shi, Zhiyi and Beale, Oliver and Rosin, Boris and Leader, Joseph and Pu, Jiantao},\n  journal={Journal of Medical Imaging},\n  volume={10},\n  number={5},\n  pages={051809--051809},\n  year={2023},\n  publisher={Society of Photo-Optical Instrumentation Engineers}\n  abstract={Purpose: To validate the effectiveness of an approach called batch-balanced focal loss (BBFL) in enhancing convolutional neural network (CNN) classification performance on imbalanced datasets. Materials and methods: BBFL combines two strategies to tackle class imbalance: (1) batch-balancing to equalize model learning of class samples and (2) focal loss to add hard-sample importance to the learning gradient. BBFL was validated on two imbalanced fundus image datasets: a binary retinal nerve fiber layer defect (RNFLD) dataset ( n = 7,258 ) and a multiclass glaucoma dataset ( n = 7,873 ). BBFL was compared to several imbalanced learning techniques, including random oversampling (ROS), cost-sensitive learning, and thresholding, based on three state-of-the-art CNNs. Accuracy, F1-score, and the area under the receiver operator characteristic curve (AUC) were used as the performance metrics for binary classification. Mean accuracy and mean F1-score were used for multiclass classification. Confusion matrices, t-distributed neighbor embedding plots, and GradCAM were used for the visual assessment of performance. Results: In binary classification of RNFLD, BBFL with InceptionV3 (93.0% accuracy, 84.7% F1, 0.971 AUC) outperformed ROS (92.6% accuracy, 83.7% F1, 0.964 AUC), cost-sensitive learning (92.5% accuracy, 83.8% F1, 0.962 AUC), and thresholding (91.9% accuracy, 83.0% F1, 0.962 AUC) and others. In multiclass classification of glaucoma, BBFL with MobileNetV2 (79.7% accuracy, 69.6% average F1 score) outperformed ROS (76.8% accuracy, 64.7% F1), cost-sensitive learning (78.3% accuracy, 67.8.8% F1), and random undersampling (76.5% accuracy, 66.5% F1). Conclusion: The BBFL-based learning method can improve the performance of a CNN model in both binary and multiclass disease classification when the data are imbalanced.}\n}"
    },
    {
      "id": "yang2022proco",
      "title": "Proco: Prototype-aware contrastive learning for long-tailed medical image classification",
      "authors": "Yang, Zhixiong and Pan, Junwen and Yang, Yanzhan and Shi, Xiaozhou and Zhou, Hong-Yu and Zhang, Zhicheng and Bian, Cheng",
      "year": "2022",
      "venue": "International conference on medical image computing and computer-assisted intervention",
      "abstract": "Medical image classification has been widely adopted in medical image analysis. However, due to the difficulty of collecting and labeling data in the medical area, medical image datasets are usually highly-imbalanced. To address this problem, previous works utilized class samples as prior for re-weighting or re-sampling but the feature representation is usually still not discriminative enough. In this paper, we adopt the contrastive learning to tackle the long-tailed medical imbalance problem. Specifically, we first propose the category prototype and adversarial proto-instance to generate representative contrastive pairs. Then, the prototype recalibration strategy is proposed to address the highly imbalanced data distribution. Finally, a unified proto-loss is designed to train our framework. The overall framework, namely as Prototype-aware Contrastive learning (ProCo), is unified as a single-stage pipeline in an end-to-end manner to alleviate the imbalanced problem in medical image classification, which is also a distinct progress than existing works as they follow the traditional two-stage pipeline. Extensive experiments on two highly-imbalanced medical image classification datasets demonstrate that our method outperforms the existing state-of-the-art methods by a large margin.",
      "bibtex": "@inproceedings{yang2022proco,\n  title={Proco: Prototype-aware contrastive learning for long-tailed medical image classification},\n  author={Yang, Zhixiong and Pan, Junwen and Yang, Yanzhan and Shi, Xiaozhou and Zhou, Hong-Yu and Zhang, Zhicheng and Bian, Cheng},\n  booktitle={International conference on medical image computing and computer-assisted intervention},\n  pages={173--182},\n  year={2022},\n  organization={Springer}\n  abstract={Medical image classification has been widely adopted in medical image analysis. However, due to the difficulty of collecting and labeling data in the medical area, medical image datasets are usually highly-imbalanced. To address this problem, previous works utilized class samples as prior for re-weighting or re-sampling but the feature representation is usually still not discriminative enough. In this paper, we adopt the contrastive learning to tackle the long-tailed medical imbalance problem. Specifically, we first propose the category prototype and adversarial proto-instance to generate representative contrastive pairs. Then, the prototype recalibration strategy is proposed to address the highly imbalanced data distribution. Finally, a unified proto-loss is designed to train our framework. The overall framework, namely as Prototype-aware Contrastive learning (ProCo), is unified as a single-stage pipeline in an end-to-end manner to alleviate the imbalanced problem in medical image classification, which is also a distinct progress than existing works as they follow the traditional two-stage pipeline. Extensive experiments on two highly-imbalanced medical image classification datasets demonstrate that our method outperforms the existing state-of-the-art methods by a large margin.}\n}"
    },
    {
      "id": "yeung2022unified",
      "title": "Unified focal loss: Generalising dice and cross entropy-based losses to handle class imbalanced medical image segmentation",
      "authors": "Yeung, Michael and Sala, Evis and Sch{\\\"o",
      "year": "2022",
      "venue": "Computerized Medical Imaging and Graphics",
      "abstract": "Automatic segmentation methods are an important advancement in medical image analysis. Machine learning techniques, and deep neural networks in particular, are the state-of-the-art for most medical image segmentation tasks. Issues with class imbalance pose a significant challenge in medical datasets, with lesions often occupying a considerably smaller volume relative to the background. Loss functions used in the training of deep learning algorithms differ in their robustness to class imbalance, with direct consequences for model convergence. The most commonly used loss functions for segmentation are based on either the cross entropy loss, Dice loss or a combination of the two. We propose the Unified Focal loss, a new hierarchical framework that generalises Dice and cross entropy-based losses for handling class imbalance. We evaluate our proposed loss function on five publicly available, class imbalanced medical imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction (DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020 (BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss function performance against six Dice or cross entropy-based loss functions, across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating that our proposed loss function is robust to class imbalance and consistently outperforms the other loss functions. Source code is available at: https://github.com/mlyg/unified-focal-loss.",
      "bibtex": "@article{yeung2022unified,\n  title={Unified focal loss: Generalising dice and cross entropy-based losses to handle class imbalanced medical image segmentation},\n  author={Yeung, Michael and Sala, Evis and Sch{\\\"o}nlieb, Carola-Bibiane and Rundo, Leonardo},\n  journal={Computerized Medical Imaging and Graphics},\n  volume={95},\n  pages={102026},\n  year={2022},\n  publisher={Elsevier}\n  abstract={Automatic segmentation methods are an important advancement in medical image analysis. Machine learning techniques, and deep neural networks in particular, are the state-of-the-art for most medical image segmentation tasks. Issues with class imbalance pose a significant challenge in medical datasets, with lesions often occupying a considerably smaller volume relative to the background. Loss functions used in the training of deep learning algorithms differ in their robustness to class imbalance, with direct consequences for model convergence. The most commonly used loss functions for segmentation are based on either the cross entropy loss, Dice loss or a combination of the two. We propose the Unified Focal loss, a new hierarchical framework that generalises Dice and cross entropy-based losses for handling class imbalance. We evaluate our proposed loss function on five publicly available, class imbalanced medical imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction (DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020 (BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss function performance against six Dice or cross entropy-based loss functions, across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating that our proposed loss function is robust to class imbalance and consistently outperforms the other loss functions. Source code is available at: https://github.com/mlyg/unified-focal-loss.}\n}"
    },
    {
      "id": "zhang2023ecl",
      "title": "Ecl: Class-enhancement contrastive learning for long-tailed skin lesion classification",
      "authors": "Zhang, Yilan and Chen, Jianqi and Wang, Ke and Xie, Fengying",
      "year": "2023",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "abstract": "Abstract not available.",
      "bibtex": "@inproceedings{zhang2023ecl,\n  title={Ecl: Class-enhancement contrastive learning for long-tailed skin lesion classification},\n  author={Zhang, Yilan and Chen, Jianqi and Wang, Ke and Xie, Fengying},\n  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n  pages={244--254},\n  year={2023},\n  organization={Springer}\n}"
    }
  ]
}