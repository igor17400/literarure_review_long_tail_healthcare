{
  "category": "Foundation Models",
  "description": "Addressing long-tailed distributions through transfer learning and efficient adaptation.",
  "papers": [
    {
      "id": "zheng2024large",
      "title": "Large-scale long-tailed disease diagnosis on radiology images",
      "authors": "Zheng, Qiaoyu and Zhao, Weike and Wu, Chaoyi and Zhang, Xiaoman and Dai, Lisong and Guan, Hengyu and Li, Yuehua and Zhang, Ya and Wang, Yanfeng and Xie, Weidi",
      "year": "2024",
      "venue": "Nature Communications",
      "abstract": "Developing a generalist radiology diagnosis system can greatly enhance clinical diagnostics. In this paper, we introduce RadDiag, a foundational model supporting 2D and 3D inputs across various modalities and anatomies, using a transformer-based fusion module for comprehensive disease diagnosis. Due to patient privacy concerns and the lack of large-scale radiology diagnosis datasets, we utilize high-quality, clinician-reviewed radiological images available online with diagnosis labels. Our dataset, RP3D-DiagDS, contains 40,936 cases with 195,010 scans covering 5568 disorders (930 unique ICD-10-CM codes). Experimentally, our RadDiag achieves 95.14% AUC on internal evaluation with the knowledge-enhancement strategy. Additionally, RadDiag can be zero-shot applied or fine-tuned to external diagnosis datasets sourced from various medical centers, demonstrating state-of-the-art results. In conclusion, we show that publicly shared medical data on the Internet is a tremendous and valuable resource that can potentially support building strong models for image understanding in healthcare.",
      "bibtex": "@article{zheng2024large,\n  title={Large-scale long-tailed disease diagnosis on radiology images},\n  author={Zheng, Qiaoyu and Zhao, Weike and Wu, Chaoyi and Zhang, Xiaoman and Dai, Lisong and Guan, Hengyu and Li, Yuehua and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},\n  journal={Nature Communications},\n  volume={15},\n  number={1},\n  pages={10147},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n  abstract={Developing a generalist radiology diagnosis system can greatly enhance clinical diagnostics. In this paper, we introduce RadDiag, a foundational model supporting 2D and 3D inputs across various modalities and anatomies, using a transformer-based fusion module for comprehensive disease diagnosis. Due to patient privacy concerns and the lack of large-scale radiology diagnosis datasets, we utilize high-quality, clinician-reviewed radiological images available online with diagnosis labels. Our dataset, RP3D-DiagDS, contains 40,936 cases with 195,010 scans covering 5568 disorders (930 unique ICD-10-CM codes). Experimentally, our RadDiag achieves 95.14% AUC on internal evaluation with the knowledge-enhancement strategy. Additionally, RadDiag can be zero-shot applied or fine-tuned to external diagnosis datasets sourced from various medical centers, demonstrating state-of-the-art results. In conclusion, we show that publicly shared medical data on the Internet is a tremendous and valuable resource that can potentially support building strong models for image understanding in healthcare.}\n}"
    },
    {
      "id": "jang2024significantly",
      "title": "Significantly improving zero-shot X-ray pathology classification via fine-tuning pre-trained image-text encoders",
      "authors": "Jang, Jongseong and Kyung, Daeun and Kim, Seung Hwan and Lee, Honglak and Bae, Kyunghoon and Choi, Edward",
      "year": "2024",
      "venue": "Scientific Reports",
      "abstract": "Deep neural networks are increasingly used in medical imaging for tasks such as pathological classification, but they face challenges due to the scarcity of high-quality, expert-labeled training data. Recent efforts have utilized pre-trained contrastive image-text models like CLIP, adapting them for medical use by fine-tuning the model with chest X-ray images and corresponding reports for zero-shot pathology classification, thus eliminating the need for pathology-specific annotations. However, most studies continue to use the same contrastive learning objectives as in the general domain, overlooking the multi-labeled nature of medical image-report pairs. In this paper, we propose a new fine-tuning strategy that includes positive-pair loss relaxation and random sentence sampling. We aim to improve the performance of zero-shot pathology classification without relying on external knowledge. Our method can be applied to any pre-trained contrastive image-text encoder and easily transferred to out-of-domain datasets without further training, as it does not use external data. Our approach consistently improves overall zero-shot pathology classification across four chest X-ray datasets and three pre-trained models, with an average macro AUROC increase of 4.3%. Additionally, our method outperforms the state-of-the-art and marginally surpasses board-certified radiologists in zero-shot classification for the five competition pathologies in the CheXpert dataset.",
      "bibtex": "@article{jang2024significantly,\n  title={Significantly improving zero-shot X-ray pathology classification via fine-tuning pre-trained image-text encoders},\n  author={Jang, Jongseong and Kyung, Daeun and Kim, Seung Hwan and Lee, Honglak and Bae, Kyunghoon and Choi, Edward},\n  journal={Scientific Reports},\n  volume={14},\n  number={1},\n  pages={23199},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n  abstract={Deep neural networks are increasingly used in medical imaging for tasks such as pathological classification, but they face challenges due to the scarcity of high-quality, expert-labeled training data. Recent efforts have utilized pre-trained contrastive image-text models like CLIP, adapting them for medical use by fine-tuning the model with chest X-ray images and corresponding reports for zero-shot pathology classification, thus eliminating the need for pathology-specific annotations. However, most studies continue to use the same contrastive learning objectives as in the general domain, overlooking the multi-labeled nature of medical image-report pairs. In this paper, we propose a new fine-tuning strategy that includes positive-pair loss relaxation and random sentence sampling. We aim to improve the performance of zero-shot pathology classification without relying on external knowledge. Our method can be applied to any pre-trained contrastive image-text encoder and easily transferred to out-of-domain datasets without further training, as it does not use external data. Our approach consistently improves overall zero-shot pathology classification across four chest X-ray datasets and three pre-trained models, with an average macro AUROC increase of 4.3%. Additionally, our method outperforms the state-of-the-art and marginally surpasses board-certified radiologists in zero-shot classification for the five competition pathologies in the CheXpert dataset.}\n}"
    },
    {
      "id": "liu2025generalist",
      "title": "A generalist medical language model for disease diagnosis assistance",
      "authors": "Liu, Xiaohong and Liu, Hao and Yang, Guoxing and Jiang, Zeyu and Cui, Shuguang and Zhang, Zhaoze and Wang, Huan and Tao, Liyuan and Sun, Yongchang and Song, Zhu and others",
      "year": "2025",
      "venue": "Nature medicine",
      "abstract": "The delivery of accurate diagnoses is crucial in healthcare and represents the gateway to appropriate and timely treatment. Although recent large language models (LLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, their effectiveness in clinical diagnosis remains unproven. Here we present MedFound, a generalist medical language model with 176 billion parameters, pre-trained on a large-scale corpus derived from diverse medical text and real-world clinical records. We further fine-tuned MedFound to learn physicians’ inferential diagnosis with a self-bootstrapping strategy-based chain-of-thought approach and introduced a unified preference alignment framework to align it with standard clinical practice. Extensive experiments demonstrate that our medical LLM outperforms other baseline LLMs and specialized models in in-distribution (common diseases), out-of-distribution (external validation) and long-tailed distribution (rare diseases) scenarios across eight specialties. Further ablation studies indicate the effectiveness of key components in our medical LLM training approach. We conducted a comprehensive evaluation of the clinical applicability of LLMs for diagnosis involving artificial intelligence (AI) versus physician comparison, AI-assistance study and human evaluation framework. Our proposed framework incorporates eight clinical evaluation metrics, covering capabilities such as medical record summarization, diagnostic reasoning and risk management. Our findings demonstrate the model’s feasibility in assisting physicians with disease diagnosis as part of the clinical workflow.",
      "bibtex": "@article{liu2025generalist,\n  title={A generalist medical language model for disease diagnosis assistance},\n  author={Liu, Xiaohong and Liu, Hao and Yang, Guoxing and Jiang, Zeyu and Cui, Shuguang and Zhang, Zhaoze and Wang, Huan and Tao, Liyuan and Sun, Yongchang and Song, Zhu and others},\n  journal={Nature medicine},\n  volume={31},\n  number={3},\n  pages={932--942},\n  year={2025},\n  publisher={Nature Publishing Group US New York}\n  abstract={The delivery of accurate diagnoses is crucial in healthcare and represents the gateway to appropriate and timely treatment. Although recent large language models (LLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, their effectiveness in clinical diagnosis remains unproven. Here we present MedFound, a generalist medical language model with 176 billion parameters, pre-trained on a large-scale corpus derived from diverse medical text and real-world clinical records. We further fine-tuned MedFound to learn physicians’ inferential diagnosis with a self-bootstrapping strategy-based chain-of-thought approach and introduced a unified preference alignment framework to align it with standard clinical practice. Extensive experiments demonstrate that our medical LLM outperforms other baseline LLMs and specialized models in in-distribution (common diseases), out-of-distribution (external validation) and long-tailed distribution (rare diseases) scenarios across eight specialties. Further ablation studies indicate the effectiveness of key components in our medical LLM training approach. We conducted a comprehensive evaluation of the clinical applicability of LLMs for diagnosis involving artificial intelligence (AI) versus physician comparison, AI-assistance study and human evaluation framework. Our proposed framework incorporates eight clinical evaluation metrics, covering capabilities such as medical record summarization, diagnostic reasoning and risk management. Our findings demonstrate the model’s feasibility in assisting physicians with disease diagnosis as part of the clinical workflow.}\n}"
    }
  ]
}