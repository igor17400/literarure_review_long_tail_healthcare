{
  "category": "Neural Architecture",
  "description": "Specialized network designs and architectural modifications for imbalanced data",
  "papers": [
    {
      "id": "de2022class",
      "title": "Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types",
      "authors": "De Angeli, Kevin and Gao, Shang and Danciu, Ioana and Durbin, Eric B and Wu, Xiao-Cheng and Stroup, Antoinette and Doherty, Jennifer and Schwartz, Stephen and Wiggins, Charles and Damesyn, Mark and others",
      "year": "2022",
      "venue": "Journal of biomedical informatics",
      "abstract": "In the last decade, the widespread adoption of electronic health record documentation has created huge opportunities for information mining. Natural language processing (NLP) techniques using machine and deep learning are becoming increasingly widespread for information extraction tasks from unstructured clinical notes. Disparities in performance when deploying machine learning models in the real world have recently received considerable attention. In the clinical NLP domain, the robustness of convolutional neural networks (CNNs) for classifying cancer pathology reports under natural distribution shifts remains understudied. In this research, we aim to quantify and improve the performance of the CNN for text classification on out-of-distribution (OOD) datasets resulting from the natural evolution of clinical text in pathology reports. We identified class imbalance due to different prevalence of cancer types as one of the sources of performance drop and analyzed the impact of previous methods for addressing class imbalance when deploying models in real-world domains. Our results show that our novel class-specialized ensemble technique outperforms other methods for the classification of rare cancer types in terms of macro F1 scores. We also found that traditional ensemble methods perform better in top classes, leading to higher micro F1 scores. Based on our findings, we formulate a series of recommendations for other ML practitioners on how to build robust models with extremely imbalanced datasets in biomedical NLP applications.",
      "bibtex": "@article{de2022class,\n  title={Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types},\n  author={De Angeli, Kevin and Gao, Shang and Danciu, Ioana and Durbin, Eric B and Wu, Xiao-Cheng and Stroup, Antoinette and Doherty, Jennifer and Schwartz, Stephen and Wiggins, Charles and Damesyn, Mark and others},\n  journal={Journal of biomedical informatics},\n  volume={125},\n  pages={103957},\n  year={2022},\n  publisher={Elsevier}\n  abstract={In the last decade, the widespread adoption of electronic health record documentation has created huge opportunities for information mining. Natural language processing (NLP) techniques using machine and deep learning are becoming increasingly widespread for information extraction tasks from unstructured clinical notes. Disparities in performance when deploying machine learning models in the real world have recently received considerable attention. In the clinical NLP domain, the robustness of convolutional neural networks (CNNs) for classifying cancer pathology reports under natural distribution shifts remains understudied. In this research, we aim to quantify and improve the performance of the CNN for text classification on out-of-distribution (OOD) datasets resulting from the natural evolution of clinical text in pathology reports. We identified class imbalance due to different prevalence of cancer types as one of the sources of performance drop and analyzed the impact of previous methods for addressing class imbalance when deploying models in real-world domains. Our results show that our novel class-specialized ensemble technique outperforms other methods for the classification of rare cancer types in terms of macro F1 scores. We also found that traditional ensemble methods perform better in top classes, leading to higher micro F1 scores. Based on our findings, we formulate a series of recommendations for other ML practitioners on how to build robust models with extremely imbalanced datasets in biomedical NLP applications.}\n}"
    },
    {
      "id": "holste2023does",
      "title": "How does pruning impact long-tailed multi-label medical image classifiers?",
      "authors": "Holste, Gregory and Jiang, Ziyu and Jaiswal, Ajay and Hanna, Maria and Minkowitz, Shlomo and Legasto, Alan C and Escalon, Joanna G and Steinberger, Sharon and Bittman, Mark and Shen, Thomas C and others",
      "year": "2023",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "abstract": "Abstract. Pruning has emerged as a powerful technique for compressing deep neural networks, reducing memory usage and inference time without significantly affecting overall performance. However, the nuanced ways in which pruning impacts model behavior are not well understood, particularly for long-tailed, multi-label datasets commonly found in clinical settings. This knowledge gap could have dangerous implications when deploying a pruned model for diagnosis, where unexpected model behavior could impact patient well-being. To fill this gap, we perform the first analysis of pruning’s effect on neural networks trained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR datasets, we examine which diseases are most affected by pruning and characterize class “forgettability” based on disease frequency and co-occurrence behavior. Further, we identify individual CXRs where uncompressed and heavily pruned models disagree, known as pruning-identified exemplars (PIEs), and conduct a human reader study to evaluate their unifying qualities. We find that radiologists perceive PIEs as having more label noise, lower image quality, and higher diagnosis difficulty. This work represents a first step toward understanding the impact of pruning on model behavior in deep long-tailed, multi-label medical image classification. All code, model weights, and data access instructions can be found at https://github.com/VITA-Group/PruneCXR.",
      "bibtex": "@inproceedings{holste2023does,\n  title={How does pruning impact long-tailed multi-label medical image classifiers?},\n  author={Holste, Gregory and Jiang, Ziyu and Jaiswal, Ajay and Hanna, Maria and Minkowitz, Shlomo and Legasto, Alan C and Escalon, Joanna G and Steinberger, Sharon and Bittman, Mark and Shen, Thomas C and others},\n  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n  pages={663--673},\n  year={2023},\n  organization={Springer}\n  abstract={Abstract. Pruning has emerged as a powerful technique for compressing deep neural networks, reducing memory usage and inference time without significantly affecting overall performance. However, the nuanced ways in which pruning impacts model behavior are not well understood, particularly for long-tailed, multi-label datasets commonly found in clinical settings. This knowledge gap could have dangerous implications when deploying a pruned model for diagnosis, where unexpected model behavior could impact patient well-being. To fill this gap, we perform the first analysis of pruning’s effect on neural networks trained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR datasets, we examine which diseases are most affected by pruning and characterize class “forgettability” based on disease frequency and co-occurrence behavior. Further, we identify individual CXRs where uncompressed and heavily pruned models disagree, known as pruning-identified exemplars (PIEs), and conduct a human reader study to evaluate their unifying qualities. We find that radiologists perceive PIEs as having more label noise, lower image quality, and higher diagnosis difficulty. This work represents a first step toward understanding the impact of pruning on model behavior in deep long-tailed, multi-label medical image classification. All code, model weights, and data access instructions can be found at https://github.com/VITA-Group/PruneCXR.}\n}"
    },
    {
      "id": "lankireddy2022new",
      "title": "A new lightweight architecture and a class imbalance aware loss function for multi-label classification of intracranial hemorrhages",
      "authors": "Lankireddy, Prabhat and Sindhura, Chitimireddy and Gorthi, Subrahmanyam",
      "year": "2022",
      "venue": "International Workshop on Machine Learning in Medical Imaging",
      "abstract": "Deep learning algorithms have proven effective in solving many medical imaging tasks in recent years. The design of lightweight neural networks is gaining importance in the medical imaging community as not many hospitals and clinics are equipped with high computational resources to deploy large deep learning algorithms. Also, medical imaging data often comes with high class imbalance and thus there is a high necessity to develop deep learning models that can address this issue. With this motivation, a resource-efficient deep learning model called Lightweight-Fully Convolutional Network (LightFCN) is developed which can be deployed in clinical settings with limited computational resources. Label Distribution Aware Margin loss (LDAM) is used in the context of medical imaging for the first time for multi-label classification with class imbalance. The proposed model has a smaller memory footprint, a smaller number of parameters, lesser inference time and fewer Floating Point Operations (FLOPS) when compared to state-of-the-art models, without compromising on performance and can be deployed in clinical settings with limited computational resources. The model and the performance of the loss function are evaluated on the task of Intracranial Hemorrhage (ICH) classification on CT scans, and the model was deployed on a Raspberry Pi 4B (8 GB), on which inference times were compared. It is found that the proposed model significantly reduced the number of model parameters by a factor of 26, and reduced the inference time by a factor of 3, when compared to the popular lightweight network MobileNetV2.",
      "bibtex": "@inproceedings{lankireddy2022new,\n  title={A new lightweight architecture and a class imbalance aware loss function for multi-label classification of intracranial hemorrhages},\n  author={Lankireddy, Prabhat and Sindhura, Chitimireddy and Gorthi, Subrahmanyam},\n  booktitle={International Workshop on Machine Learning in Medical Imaging},\n  pages={397--405},\n  year={2022},\n  organization={Springer}\n  abstract={Deep learning algorithms have proven effective in solving many medical imaging tasks in recent years. The design of lightweight neural networks is gaining importance in the medical imaging community as not many hospitals and clinics are equipped with high computational resources to deploy large deep learning algorithms. Also, medical imaging data often comes with high class imbalance and thus there is a high necessity to develop deep learning models that can address this issue. With this motivation, a resource-efficient deep learning model called Lightweight-Fully Convolutional Network (LightFCN) is developed which can be deployed in clinical settings with limited computational resources. Label Distribution Aware Margin loss (LDAM) is used in the context of medical imaging for the first time for multi-label classification with class imbalance. The proposed model has a smaller memory footprint, a smaller number of parameters, lesser inference time and fewer Floating Point Operations (FLOPS) when compared to state-of-the-art models, without compromising on performance and can be deployed in clinical settings with limited computational resources. The model and the performance of the loss function are evaluated on the task of Intracranial Hemorrhage (ICH) classification on CT scans, and the model was deployed on a Raspberry Pi 4B (8 GB), on which inference times were compared. It is found that the proposed model significantly reduced the number of model parameters by a factor of 26, and reduced the inference time by a factor of 3, when compared to the popular lightweight network MobileNetV2.}\n}"
    },
    {
      "id": "li2022flat",
      "title": "Flat-aware cross-stage distilled framework for imbalanced medical image classification",
      "authors": "Li, Jinpeng and Chen, Guangyong and Mao, Hangyu and Deng, Danruo and Li, Dong and Hao, Jianye and Dou, Qi and Heng, Pheng-Ann",
      "year": "2022",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "abstract": "Medical data often follow imbalanced distributions, which poses a long-standing challenge for computer-aided diagnosis systems built upon medical image classification. Most existing efforts are conducted by applying re-balancing methods for the collected training samples, which improves the predictive performance for the minority class but at the cost of decreasing the performance for the majority. To address this paradox, we adopt a flat-aware cross-stage distilled framework (FCD), where we first search for flat local minima of the base training objective function on the original imbalanced dataset, and then continuously finetune this classifier within the flat region on the re-balanced one. To further prevent the performance decreasing for the majority, we propose a cross-stage distillation regularizing term to promote the optimized features to remain in the common optimal subspace. Extensive experiments on two imbalanced medical image datasets demonstrate the effectiveness of our proposed framework and its generality in improving the performance of existing imbalanced methods. The code of this work will be released publicly.",
      "bibtex": "@inproceedings{li2022flat,\n  title={Flat-aware cross-stage distilled framework for imbalanced medical image classification},\n  author={Li, Jinpeng and Chen, Guangyong and Mao, Hangyu and Deng, Danruo and Li, Dong and Hao, Jianye and Dou, Qi and Heng, Pheng-Ann},\n  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n  pages={217--226},\n  year={2022},\n  organization={Springer}\n  abstract={Medical data often follow imbalanced distributions, which poses a long-standing challenge for computer-aided diagnosis systems built upon medical image classification. Most existing efforts are conducted by applying re-balancing methods for the collected training samples, which improves the predictive performance for the minority class but at the cost of decreasing the performance for the majority. To address this paradox, we adopt a flat-aware cross-stage distilled framework (FCD), where we first search for flat local minima of the base training objective function on the original imbalanced dataset, and then continuously finetune this classifier within the flat region on the re-balanced one. To further prevent the performance decreasing for the majority, we propose a cross-stage distillation regularizing term to promote the optimized features to remain in the common optimal subspace. Extensive experiments on two imbalanced medical image datasets demonstrate the effectiveness of our proposed framework and its generality in improving the performance of existing imbalanced methods. The code of this work will be released publicly.}\n}"
    },
    {
      "id": "yang2024deep",
      "title": "Deep reinforcement learning for multi-class imbalanced training: applications in healthcare",
      "authors": "Yang, Jenny and El-Bouri, Rasheed and O’Donoghue, Odhran and Lachapelle, Alexander S and Soltan, Andrew AS and Eyre, David W and Lu, Lei and Clifton, David A",
      "year": "2024",
      "venue": "Machine Learning",
      "abstract": "With the rapid growth of memory and computing power, datasets are becoming increasingly complex and imbalanced. This is especially severe in the context of clinical data, where there may be one rare event for many cases in the majority class. We introduce an imbalanced classification framework, based on reinforcement learning, for training extremely imbalanced data sets, and extend it for use in multi-class settings. We combine dueling and double deep Q-learning architectures, and formulate a custom reward function and episode-training procedure, specifically with the capability of handling multi-class imbalanced training. Using real-world clinical case studies, we demonstrate that our proposed framework outperforms current state-of-the-art imbalanced learning methods, achieving more fair and balanced classification, while also significantly improving the prediction of minority classes.",
      "bibtex": "@article{yang2024deep,\n  title={Deep reinforcement learning for multi-class imbalanced training: applications in healthcare},\n  author={Yang, Jenny and El-Bouri, Rasheed and O’Donoghue, Odhran and Lachapelle, Alexander S and Soltan, Andrew AS and Eyre, David W and Lu, Lei and Clifton, David A},\n  journal={Machine Learning},\n  volume={113},\n  number={5},\n  pages={2655--2674},\n  year={2024},\n  publisher={Springer}\n  abstract={With the rapid growth of memory and computing power, datasets are becoming increasingly complex and imbalanced. This is especially severe in the context of clinical data, where there may be one rare event for many cases in the majority class. We introduce an imbalanced classification framework, based on reinforcement learning, for training extremely imbalanced data sets, and extend it for use in multi-class settings. We combine dueling and double deep Q-learning architectures, and formulate a custom reward function and episode-training procedure, specifically with the capability of handling multi-class imbalanced training. Using real-world clinical case studies, we demonstrate that our proposed framework outperforms current state-of-the-art imbalanced learning methods, achieving more fair and balanced classification, while also significantly improving the prediction of minority classes.}\n}"
    },
    {
      "id": "wang2023dhc",
      "title": "Dhc: Dual-debiased heterogeneous co-training framework for class-imbalanced semi-supervised medical image segmentation",
      "authors": "Wang, Haonan and Li, Xiaomeng",
      "year": "2023",
      "venue": "International conference on medical image computing and computer-assisted intervention",
      "abstract": "The volume-wise labeling of 3D medical images is expertise-demanded and time-consuming; hence semi-supervised learning (SSL) is highly desirable for training with limited labeled data. Imbalanced class distribution is a severe problem that bottlenecks the real-world application of these methods but was not addressed much. Aiming to solve this issue, we present a novel Dual-debiased Heterogeneous Co-training (DHC) framework for semi-supervised 3D medical image segmentation. Specifically, we propose two loss weighting strategies, namely Distribution-aware Debiased Weighting (DistDW) and Difficulty-aware Debiased Weighting (DiffDW), which leverage the pseudo labels dynamically to guide the model to solve data and learning biases. The framework improves significantly by co-training these two diverse and accurate sub-models. We also introduce more representative benchmarks for class-imbalanced semi-supervised medical image segmentation, which can fully demonstrate the efficacy of the class-imbalance designs. Experiments show that our proposed framework brings significant improvements by using pseudo labels for debiasing and alleviating the class imbalance problem. More importantly, our method outperforms the state-of-the-art SSL methods, demonstrating the potential of our framework for the more challenging SSL setting. Code and models are available at: https://github.com/xmed-lab/DHC.",
      "bibtex": "@inproceedings{wang2023dhc,\n  title={Dhc: Dual-debiased heterogeneous co-training framework for class-imbalanced semi-supervised medical image segmentation},\n  author={Wang, Haonan and Li, Xiaomeng},\n  booktitle={International conference on medical image computing and computer-assisted intervention},\n  pages={582--591},\n  year={2023},\n  organization={Springer}\n  abstract={The volume-wise labeling of 3D medical images is expertise-demanded and time-consuming; hence semi-supervised learning (SSL) is highly desirable for training with limited labeled data. Imbalanced class distribution is a severe problem that bottlenecks the real-world application of these methods but was not addressed much. Aiming to solve this issue, we present a novel Dual-debiased Heterogeneous Co-training (DHC) framework for semi-supervised 3D medical image segmentation. Specifically, we propose two loss weighting strategies, namely Distribution-aware Debiased Weighting (DistDW) and Difficulty-aware Debiased Weighting (DiffDW), which leverage the pseudo labels dynamically to guide the model to solve data and learning biases. The framework improves significantly by co-training these two diverse and accurate sub-models. We also introduce more representative benchmarks for class-imbalanced semi-supervised medical image segmentation, which can fully demonstrate the efficacy of the class-imbalance designs. Experiments show that our proposed framework brings significant improvements by using pseudo labels for debiasing and alleviating the class imbalance problem. More importantly, our method outperforms the state-of-the-art SSL methods, demonstrating the potential of our framework for the more challenging SSL setting. Code and models are available at: https://github.com/xmed-lab/DHC.}\n}"
    }
  ]
}